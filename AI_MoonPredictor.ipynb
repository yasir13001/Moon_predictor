{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing a package\n",
    "#!pip3 install <package name> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. remove jiwani hard coding apply any condition so that jiwani will be selected automatically...........done\n",
    "# get islamic month and year from internet and put as an input\n",
    "# 3. Make a method to process all files according to their Islamic Month name and Islamic date automatically\n",
    "# 4. Calculate Parameters and recheck its accuracy with data \n",
    "# 5. Make GUI interface\n",
    "# 6. Make it customizable code and reusable code apply OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18de828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math \n",
    "import os\n",
    "from fpdf import FPDF\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c2c52f9",
   "metadata": {
    "code_folding": [
     0,
     2,
     9,
     10,
     67,
     73,
     86,
     105,
     116,
     196
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import webbrowser\n",
    "\n",
    "class MoonCalc:\n",
    "    def __init__(self, file_path, date, Month, year, dst):\n",
    "        self.path = file_path.replace('\"', '')\n",
    "        self.date = date.replace('\"', '')\n",
    "        self.month = Month.replace('\"', '')\n",
    "        self.year = year.replace('\"', '')\n",
    "        self.dst = dst.replace('\"', '') if dst else None\n",
    "\n",
    "    def data(self, *args):\n",
    "        def set_axis(df):\n",
    "            columns = [\"year\", \"h\", \"cd\", \"conj\", \"f\", \"wk\", \"mon\", \"day\", \"set\", \"Saz\", \"age\",\n",
    "                       \"Alt\", \"Maz\", \"dz\", \"Mag\", \"El\", \"mset\", \"lag\", \"best\", \"cat\"]\n",
    "            df.columns = columns\n",
    "            return df\n",
    "\n",
    "        def illum(a):\n",
    "            return round(50 * (1 - math.cos(math.radians(a))), 1)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_fwf(os.path.join(args[0], args[1]))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {args[1]}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = set_axis(df)\n",
    "        dfa = df.drop(['f', 'Mag', 'wk'], axis=1)\n",
    "        dfs = dfa.loc[:, :'conj']\n",
    "        dfd = dfa.loc[:, 'mon':'cat']\n",
    "\n",
    "        dfd = dfd.bfill()\n",
    "        dfs = dfs.ffill()\n",
    "\n",
    "        dfg = dfs.combine_first(dfd)\n",
    "        dfg.drop_duplicates(inplace=True)\n",
    "        dfg.dropna(inplace=True)\n",
    "\n",
    "        for x in ['conj', 'set', 'mset', 'best']:\n",
    "            dfg[x] = dfg[x].replace(' ', ':', regex=True)\n",
    "\n",
    "        for x in ['cd', 'day', 'year', 'lag', 'Alt', 'Saz', 'dz', 'Maz']:\n",
    "            dfg[x] = dfg[x].astype(int).astype(str)\n",
    "\n",
    "        dfg['mon'] = dfg['mon'].str[:3]\n",
    "        dfg['h'] = dfg['h'].str[:3]\n",
    "        dfg['date'] = pd.to_datetime(dfg['day'] + dfg['mon'] + dfg['year'], format='%d%b%Y')\n",
    "        dfg.set_index('date', inplace=True)\n",
    "\n",
    "        dfg['conj_time'] = pd.to_datetime(dfg['cd'] + dfg['h'] + dfg['year'] + ' ' + dfg['conj'])\n",
    "\n",
    "        dfg['Station'] = args[1].split('.', 1)[0] if args else self.loc\n",
    "\n",
    "        dfg['El'] = dfg['El'].astype(int)\n",
    "        dfg['ilum'] = dfg['El'].apply(illum)\n",
    "\n",
    "        return dfg\n",
    "\n",
    "    def sort(self, *args):\n",
    "        df = self.data(args[0], args[1])\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = df[['Station', 'set', 'lag', 'Alt', 'Saz', 'dz', 'El', 'ilum', 'cat', 'age', 'conj_time']]\n",
    "        df['Station'] = df['Station'].astype(\"category\").cat.set_categories(sorted(df['Station'].unique()))\n",
    "        return df\n",
    "\n",
    "    def all_files(self):\n",
    "        df = pd.DataFrame()\n",
    "        if os.path.exists(self.path):\n",
    "            for root, dirs, files in os.walk(self.path):\n",
    "                for filename in files:\n",
    "                    d = self.sort(root, filename)\n",
    "                    if not d.empty:\n",
    "                        df = pd.concat([df, d], ignore_index=False)\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Directory does not exist\")\n",
    "            return df\n",
    "\n",
    "    def calculate(self):\n",
    "        dfs = self.all_files()\n",
    "        dfd = pd.DataFrame()\n",
    "        if not dfs.empty:\n",
    "            dfs['date'] = dfs.index\n",
    "            dfs.set_index('date', inplace=True)\n",
    "            dfs.index = pd.to_datetime(dfs.index)\n",
    "\n",
    "            target_date = pd.to_datetime(self.date)\n",
    "            if target_date in dfs.index:\n",
    "                daily_df = dfs.loc[target_date]\n",
    "                daily_df = daily_df.sort_values('Station')\n",
    "\n",
    "                dfd = daily_df.loc[:, :'cat']\n",
    "                dfd['Station'] = dfd['Station'].astype(str) + \" (\" + dfd['set'].astype(str) + \")\"\n",
    "                dfd.drop(columns=\"set\", inplace=True)\n",
    "                \n",
    "\n",
    "                dfd.rename(columns={\n",
    "                    'Station': 'STATION(Sunset)',\n",
    "                    'lag': 'LAG TIME(Minutes)',\n",
    "                    'Alt': 'MOON ALTITUDE(Degrees)',\n",
    "                    'Saz': 'SUN_AZIMUTH(Degrees)',\n",
    "                    'dz': 'DAZ(Degrees)',\n",
    "                    'El': 'ELONGATION(Degrees)',\n",
    "                    'ilum': 'ILLUMINATION(%)',\n",
    "                    'cat': 'CRITERION'\n",
    "                }, inplace=True)\n",
    "\n",
    "        return dfd\n",
    "\n",
    "    def Select_city(self):\n",
    "        dfs = self.all_files()\n",
    "        if dfs.empty:\n",
    "            return {}\n",
    "\n",
    "        dfs.index = pd.to_datetime(dfs.index)\n",
    "        target_date = pd.to_datetime(self.date)\n",
    "\n",
    "        if target_date not in dfs.index:\n",
    "            print(\"Max df is not selected\")\n",
    "            return {}\n",
    "\n",
    "        df_today = dfs.loc[target_date].sort_values(\"Station\")\n",
    "        df_today = df_today[df_today[\"set\"] == df_today[\"set\"].max()]\n",
    "\n",
    "        return {\n",
    "            \"age\": df_today.age.values[0].split(\" \"),\n",
    "            \"dt\": df_today.conj_time.dt.strftime(\"%d-%m-%Y\").values[0],\n",
    "            \"tm\": df_today.conj_time.dt.strftime(\"%H:%M:%S\").values[0],\n",
    "            \"city\": df_today.Station.values[0]\n",
    "        }\n",
    "    \n",
    "    def pdf(self):\n",
    "        Format = \"Arial\"        \n",
    "        data = {'Station':'  STATION    (Sunset)','lag':'LAG TIME  (Min)','Alt':'MOON ALTITUDE   (Deg)', \n",
    "                                      'Saz':'SUN_AZIMUTH (Deg)',\n",
    "                                      'dz':'DAZ   (Deg)  ',\n",
    "                                      'El':'ELONGATION  (Deg)','ilum':'ILLUMINATION  (%)',\n",
    "                                      'cat':'CRITERION   '}\n",
    "        df = pd.DataFrame()\n",
    "        df = self.calculate()\n",
    "        if df.empty == True: return print(\"Date not Found\") \n",
    "        Date = datetime.strptime(self.date,\"%Y-%m-%d\")\n",
    "        Date =Date.strftime(\"%d-%m-%Y\")\n",
    "        pdf = PDF(self.path, self.date, self.month, self.year , self.dst ,'L', 'mm', 'A4')\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(Format,'B',11)\n",
    "        li = []\n",
    "        for x in data.values():li.append(x)\n",
    "        width = [40,30,38,33,22,31,33,26,40,40]\n",
    "        start = 25\n",
    "        pdf.x = start\n",
    "        offset = pdf.x + width[0]\n",
    "        sx = pdf.x\n",
    "        i = 0\n",
    "        top = 40\n",
    "        pdf.y = top\n",
    "        for head in li:    \n",
    "            pdf.multi_cell(width[i],7,head,border = 1,align = \"C\")\n",
    "            # Reset y coordinate\n",
    "            pdf.y = top\n",
    "            # Move to computed offset    \n",
    "            pdf.x = offset\n",
    "            i += 1\n",
    "            offset = offset+ width[i]\n",
    "        h = pdf.font_size * 2.5\n",
    "        pdf.y = 54\n",
    "        pdf.set_font(Format,'',11)\n",
    "        for index, row in df.iterrows():\n",
    "            i = 0\n",
    "            pdf.x = start\n",
    "            for data in row.values:\n",
    "                pdf.cell(width[i], h, str(data),border = 1,align='C') # write each data for the row in its cell\n",
    "                i +=1  \n",
    "            pdf.ln()      \n",
    "        ls = [\"(A)  Easily visible\",\n",
    "                         \"(B) Visible under perfect conditions\",\n",
    "                         \"(C)  May need optical aid to find the crescent Moon\",\n",
    "                        \"(D)  Will need optical aid to find the crescent Moon\",\n",
    "                        \"(E)  Not visible with a telescope\",\n",
    "                        \"(F)  Not visible, below the Danjon limit\"]\n",
    "        \n",
    "        pdf.ln()\n",
    "        pdf.set_font(Format, 'BU', 12)\n",
    "        h = 5\n",
    "        pdf.ln()\n",
    "        pdf.set_font(Format, '', 11)\n",
    "        if self.dst:\n",
    "            pdf.output(self.dst+\"\\\\\"+Date+\".pdf\",'F')\n",
    "            webbrowser.open_new(self.dst+\"\\\\\"+Date+'.pdf')\n",
    "        else:\n",
    "            pdf.output(Date+'.pdf','F') # save pdf\n",
    "            webbrowser.open_new(Date+'.pdf') # open pdf in browser  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2981080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDF(FPDF, MoonCalc):\n",
    "    def __init__(self, file_path, date, Month, year, dst, *args, **kwargs):\n",
    "        # Initialize FPDF\n",
    "        FPDF.__init__(self, *args, **kwargs)  \n",
    "        \n",
    "        # Initialize MoonCalc with required parameters\n",
    "        MoonCalc.__init__(self, file_path, date, Month, year, dst)\n",
    "\n",
    "    \n",
    "    def footer(self):\n",
    "        self.set_y(-27)\n",
    "        Format = \"Arial\"\n",
    "        \n",
    "        # Visibility Criterion\n",
    "        ls = [\n",
    "            \"(A)  Easily visible\",\n",
    "            \"(B)  Visible under perfect conditions\",\n",
    "            \"(C)  May need optical aid to find the crescent Moon\",\n",
    "            \"(D)  Will need optical aid to find the crescent Moon\",\n",
    "            \"(E)  Not visible with a telescope\",\n",
    "            \"(F)  Not visible, below the Danjon limit\"\n",
    "        ]\n",
    "\n",
    "        self.set_font(Format, 'BU', 12)\n",
    "        self.cell(297, 5, \"Visibility Criterion:\", ln=1, align='L')\n",
    "        self.ln(2)\n",
    "\n",
    "        self.set_font(Format, '', 11)\n",
    "        sp = \"  \"\n",
    "        self.multi_cell(280, 5, txt=sp.join(ls), align='L')\n",
    "        \n",
    "        self.set_font(Format, 'I', 8)\n",
    "        self.cell(270, 10, 'Computer Generated', 0, 0, 'R')\n",
    "\n",
    "        self.ln(5)\n",
    "\n",
    "    def header(self):\n",
    "        data = self.Select_city()\n",
    "        age = data[\"age\"]\n",
    "        dt = data[\"dt\"]\n",
    "        tm = data[\"tm\"]\n",
    "        city = data[\"city\"]\n",
    "\n",
    "        Format = \"Arial\"        \n",
    "\n",
    "        Date = datetime.strptime(self.date, \"%Y-%m-%d\")\n",
    "        Date = Date.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        self.set_font(Format, 'B', 16)\n",
    "        h = 7\n",
    "        w = 297\n",
    "        self.cell(w, h, txt=\"PARAMETERS OF THE NEW MOON \" + self.month + \" \" + self.year, ln=1, align='C')\n",
    "        self.cell(w, h, txt=\"AT THE TIME OF SUNSET ON \" + Date, ln=1, align='C')\n",
    "        self.cell(w, h, txt=f\"(Conjunction on {dt} {tm} PST) \", ln=1, align='C')\n",
    "        self.cell(w, h, txt = f\"Moon Age at the time of Sunset on {Date} ({city}): {age[0]} hrs {age[1]} mins\",ln = 1, align = 'C')\n",
    "        self.ln()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ab4ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hijri_date(date):\n",
    "    \"\"\"\n",
    "    Convert a Gregorian date (YYYY-MM-DD) to an Islamic (Hijri) date and get the next Islamic month.\n",
    "    \n",
    "    :param georgian_date: str, Gregorian date in 'YYYY-MM-DD' format\n",
    "    :return: dict, Hijri date details including next Islamic month\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert date from YYYY-MM-DD to DD-MM-YYYY for API\n",
    "        converted_date =date\n",
    "        \n",
    "        # API URL with formatted date\n",
    "        url = f\"https://api.aladhan.com/v1/gToH/{converted_date}?calendarMethod=UAQ\"\n",
    "        \n",
    "        # Send GET request\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()  # Convert response to JSON\n",
    "            \n",
    "            # Extract Hijri date details\n",
    "            hijri_date = data[\"data\"][\"hijri\"][\"date\"]  # Example: \"28-08-1446\"\n",
    "            hijri_month = data[\"data\"][\"hijri\"][\"month\"][\"en\"].upper()  # Convert to uppercase\n",
    "            hijri_day = data[\"data\"][\"hijri\"][\"day\"]  # Example: \"28\"\n",
    "            hijri_year = int(hijri_date.split('-')[2])  # Convert year to integer\n",
    "            \n",
    "            # Get current Hijri month number\n",
    "            hijri_month_number = data[\"data\"][\"hijri\"][\"month\"][\"number\"]  # Example: 8 for Sha'ban\n",
    "            \n",
    "            # List of Islamic months in uppercase\n",
    "            ISLAMIC_MONTHS = [\n",
    "                \"MUHARRAM\", \"SAFAR\", \"RABI UL AWWAL\", \"RABI US SANI\",\n",
    "                \"JUMADI UL-AWWAL\", \"JUMADI US SANI\", \"RAJAB\", \"SHABAN\",\n",
    "                \"RAMADAN\", \"SHAWWAL\", \"ZUL-QADDAH\", \"ZUL-HIJJAH\"\n",
    "            ]\n",
    "            \n",
    "            # Calculate next Islamic month\n",
    "            next_hijri_month = ISLAMIC_MONTHS[hijri_month_number % 12]  # Modulo to cycle months\n",
    "            \n",
    "            # If next month is MUHARRAM, increment the Hijri year\n",
    "            if next_hijri_month == \"MUHARRAM\":\n",
    "                hijri_year += 1\n",
    "            \n",
    "            return {\n",
    "                \"hijri_day\": hijri_day,\n",
    "                \"hijri_month\": next_hijri_month,\n",
    "                \"hijri_year\": str(hijri_year)\n",
    "            }\n",
    "        else:\n",
    "            return {\"error\": \"Failed to fetch Hijri date\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96b7003d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_pdf(path, date, dst):\n",
    "#     path = \"D:/code/Moon_predictor/Data_2035\"\n",
    "#     date = \"28-02-2025\"\n",
    "#     dst = 'D:/Output'\n",
    "    hijri_data = get_hijri_date(date)\n",
    "    month = hijri_data['hijri_month']\n",
    "    year = hijri_data['hijri_year']\n",
    "    date_obj = datetime.strptime(date, \"%d-%m-%Y\")    \n",
    "    # Convert to YYYY-MM-DD format\n",
    "    converted_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "    Moon = MoonCalc(path,converted_date,month,year +\" AH\",dst)\n",
    "    Moon.pdf()\n",
    "generate_pdf(\"Data_2035\",\"28-02-2025\",'Output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cca018ed-e7cd-499d-9065-addba621bd8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "mistral-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/mistral-7b/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m     hf_hub_download(\n\u001b[0;32m    425\u001b[0m         path_or_repo_id,\n\u001b[0;32m    426\u001b[0m         filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    427\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    428\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    429\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    430\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    431\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    432\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    433\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    434\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    435\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    436\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    437\u001b[0m     )\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[0;32m    962\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    963\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[0;32m    965\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m    966\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    967\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    968\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    969\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[0;32m    970\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m    971\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m    972\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m    973\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    974\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[0;32m    976\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    977\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    978\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:1068\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:1596\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m   1593\u001b[0m ):\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1485\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[0;32m   1486\u001b[0m     )\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1402\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1403\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1404\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m   1405\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1406\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1407\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1408\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1409\u001b[0m )\n\u001b[0;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    286\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    287\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    288\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    290\u001b[0m     )\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 309\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m     )\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67ff8001-702cb8b52a5d4e342d0f92e0;a809cdd7-e54b-448f-8fbe-0a23a1b71abc)\n\nRepository Not Found for url: https://huggingface.co/mistral-7b/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this if you're using a different Mistral model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Download the tokenizer and model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel and tokenizer downloaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:946\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[0;32m    948\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:778\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[0;32m    777\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 778\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    779\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m    780\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[0;32m    781\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    782\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    783\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    784\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    785\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    786\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    787\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    788\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    789\u001b[0m     _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    790\u001b[0m     _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m     _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    792\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    793\u001b[0m )\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    210\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\utils\\hub.py:456\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    457\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: mistral-7b is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Specify the model name from Hugging Face\n",
    "model_name = \"mistral-7b\"  # Change this if you're using a different Mistral model\n",
    "\n",
    "# Download the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(\"Model and tokenizer downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28feb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14024\\1718431733.py:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  model_path = \"C:\\\\Users\\Administrator\\.ollama\\models\"  # Update this path to where your model is saved locally\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14024\\1718431733.py:3: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  model_path = \"C:\\\\Users\\Administrator\\.ollama\\models\"  # Update this path to where your model is saved locally\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'C:\\Users\\Administrator\\.ollama\\models'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'C:\\Users\\Administrator\\.ollama\\models' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAdministrator\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.ollama\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update this path to where your model is saved locally\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_command_with_mistral\u001b[39m(command_str):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1028\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1025\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class_fast\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepseek\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2046\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[1;32m-> 2046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2047\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2049\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2050\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2051\u001b[0m     )\n\u001b[0;32m   2053\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load tokenizer for 'C:\\Users\\Administrator\\.ollama\\models'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'C:\\Users\\Administrator\\.ollama\\models' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = \"C:\\\\Users\\Administrator\\.ollama\\models\"  # Update this path to where your model is saved locally\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    \n",
    "\n",
    "def parse_command_with_mistral(command_str):\n",
    "    \"\"\"\n",
    "    This function will send the command to Mistral to extract input params.\n",
    "    It expects a string like: 'Generate pdf for input dir: Data_2035, Date: 28-02-2025, Output dir: Output'\n",
    "    and return parsed parameters as a tuple (input_dir, date, output_dir).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the prompt for Mistral to understand\n",
    "    prompt = f\"Extract the input parameters from the following command:\\n{command_str}\\n\"\n",
    "    \n",
    "    # Encode the prompt and send to the model\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=150)\n",
    "\n",
    "    # Decode the model's response\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Now, parse the generated text to extract the parameters\n",
    "    # Example expected output: \"Data_2035, 28-02-2025, Output\"\n",
    "    parsed_params = generated_text.split(\",\")  # Assuming the response is comma-separated\n",
    "    \n",
    "    if len(parsed_params) == 3:\n",
    "        input_dir = parsed_params[0].strip()\n",
    "        date = parsed_params[1].strip()\n",
    "        output_dir = parsed_params[2].strip()\n",
    "        return input_dir, date, output_dir\n",
    "    else:\n",
    "        raise ValueError(\"Parsing failed. Expected format: 'input_dir, date, output_dir'\")\n",
    "\n",
    "def generate_pdf(input_dir, date, output_dir):\n",
    "    \"\"\"\n",
    "    This is the function that processes the input params and generates the PDF.\n",
    "    For demonstration purposes, it's just printing out the values.\n",
    "    \"\"\"\n",
    "    print(f\"Generating PDF for:\\nInput Directory: {input_dir}\\nDate: {date}\\nOutput Directory: {output_dir}\")\n",
    "\n",
    "# Example usage\n",
    "command = \"Generate pdf for input dir: Data_2035, Date: 28-02-2025, Output dir: Output\"\n",
    "input_dir, date, output_dir = parse_command_with_mistral(command)\n",
    "\n",
    "# Now pass the parsed params to the generate_pdf function\n",
    "generate_pdf(input_dir, date, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt()\n",
    "params = generate_inputs(prompt)\n",
    "\n",
    "if params:\n",
    "    generate_pdf(params['path'], params['date'], params['dst'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
